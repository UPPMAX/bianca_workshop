# Lesson plan

- Date: 2024-11-11
- Course: Intermediate Bianca
- Teacher: Richel
- [Reflection](../../reflections/20241111/20241111_richel.md)

## Schedule

New is:

- file transfer is now done by Pavlin
- teaching Slurm is taken over by me

When | Who  | What                                 |Status
-----|------|--------------------------------------|------
9:00 | R    | Introduction                         |2/10
9:10 | R->P | transferring files to and from Bianca|Not mine
10:00| .    | Break                                |.
10:15| R->P | Transferring files to and from Bianca|Not mine
10:35| D->R | Slurm jobs                           |1/10
11:00| .    | Break                                |.
11:15| D->R | Slurm jobs                           |1/10
12:00| .    | Lunch                                |.
13:00| B    | Software and packages installation   |Not mine
13:45| .    | Break                                |.
14:00| BR   | IDEs on Bianca                       |3/10
14:45| .    | Break                                |.
15:00| L    | NAISS-SENS summary                   |Not mine
15:30| R    | Summary                              |2/10
15:35| R    | Evaluation                           |1/10
15:45| All  | Optional Q/A and[extra material      |Done
16:00| .    | END                                  |Done

Most preparation will go to Slurm jobs. I will:
collect/infer Slurm learning objectives from current
basic and intermediate courses.

> Learning objectives Slurm basic:
>
> - Run simple jobs in the batch system
> - Run interactively on compute nodes
> - See when to run interactive and when to use batch system
> - Check the progress of their jobs

> Learning objectives Slurm intermediate  :
>
> - Understand what Slurm is
> - Learn to submit jobs to the Slurm queue
> - Learn about the most useful Slurm options and commands
> - Verify the CPU and memory usage of jobs

I will refine this to the following learning objectives
for Slurm intermediate  :

- [Remove, I will teach at Apply level] Understand what Slurm is
- [Remove, already done in Basic] Learn to submit jobs to the Slurm queue
- [Need to refine: what is 'useful'?] Learn about the most useful Slurm options and commands
- [Most interesting] Verify the CPU and memory usage of jobs

Resulting in:

- See the CPU and memory usage of jobs
- Know how to set up jobs efficiently

Looking at the course material, including a
[PDF](https://github.com/UPPMAX/bianca_workshops/blob/main/docs/presentations/Bianca-Slurm-2023-12-Diana.pdf),
I infer more learning objectives:

- Schedule dependent jobs
- Use `$SNIC_TMP` for I/O intensive jobs
- Schedule a multi-threaded job using OpenMP
- Schedule jobs with GPU nodes
- Schedule a multi-node job using MPI
- Use job arrays
- Understand Snakemake
- Understand Nextflow

Here I sift through what is reasonable:

- [KEEP] Schedule dependent jobs: seems fun
- [REMOVE] Use `$SNIC_TMP` for I/O intensive jobs: never seen numbers of its
  importance, no code to prove its use case
- [REMOVE] Schedule a multi-threaded job using OpenMP: how to teach this?
  It is just a copy-paste of a script. Add it to the UPPMAX doc instead
  - [ ] Add to UPPMAX doc
- Schedule jobs with GPU nodes: how to teach this?
  It is just a copy-paste of a script. Add it to the UPPMAX doc instead
  - [ ] Add to UPPMAX doc
- Schedule a multi-node job using MPI: how to teach this?
  It is just a copy-paste of a script. Add it to the UPPMAX doc instead
  - [ ] Add to UPPMAX doc
- [KEEP] Use job arrays
- [REMOVE] Understand Snakemake: remove, because I want to limit
  to one build system
- [KEEP] Understand Nextflow: pick over Snakemake as it is more powerful

This results in:

- I can see the CPU and memory usage of jobs
- I understand how to set up jobs efficiently
- I can schedule a minimal workflow of jobs that depend on each other using Slurm
- I can schedule a minimal workflow of jobs that depend on each other using Nextflow
- I can run replicate jobs using Slurm job arrays

Taking a look at the state of the existing material,
I find three files with the word `slurm` in them.
I will use:

- `efficient_jobs.md`:
- `complex_jobs.md`
- `replicate_jobs.md`
